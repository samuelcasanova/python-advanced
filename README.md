# Python Advanced To-Do API with Celery

A robust FastAPI application demonstrating advanced Python patterns, including background task processing with Celery, scheduled jobs, and a reverse proxy setup with Nginx.

## üöÄ Features

- **FastAPI Backend**: Complete REST API for managing To-Do items.
- **Asynchronous Tasks**: Background processing for emails and CSV exports using Celery.
- **Scheduled Jobs**: Automated daily summaries using Celery Beat.
- **Monitoring**: Real-time task monitoring with Flower.
- **Infrastructure**: Proxying via Nginx and containerization with Docker Compose.
- **Persistence**: SQLite database for tasks and Redis as a message broker.

## üõ†Ô∏è Tech Stack

- **Linter/Formatter**: Flake8, Autopep8
- **Backend**: FastAPI, Pydantic, SQLAlchemy
- **Task Queue**: Celery, Redis
- **Reverse Proxy**: Nginx
- **Monitoring**: Flower

## üìã Prerequisites

- Docker and Docker Compose installed.

## üöÄ Setup & Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd python-advanced
   ```

2. **Start the containers**:
   ```bash
   docker compose up -d --build
   ```

3. **Populate initial data**:
   ```bash
   ./populate_data.sh
   ```

## üåê Service Endpoints

- **API**: [http://localhost:8080](http://localhost:8080)
- **Interactive Docs (Swagger UI)**: [http://localhost:8080/docs](http://localhost:8080/docs)
- **Flower (Celery Monitor)**: [http://localhost:5555](http://localhost:5555)

## ‚ö° Manual Actions

### Queue Daily Summary Manually
To trigger the daily summary generation immediately without waiting for the schedule:
```bash
docker compose exec api celery -A celery_app.celery call generate_daily_summary
```
*The result will be saved in the `./shared/daily_summary.json` file.*

### Test CSV Export
Run the provided test script to trigger an export, poll for completion, and download the resulting CSV:
```bash
./test_export.sh
```

### Check Flake8 Compliance
To verify code formatting:
```bash
./.venv/bin/flake8 .
```

## üìÖ Dynamic Task Scheduling

The application uses `sqlalchemy-celery-beat` for a database-backed scheduler. This allows you to manage periodic tasks via the API without restarting services.

### List all scheduled tasks
```bash
curl -X GET http://localhost:8080/scheduler/tasks
```

### Create or Update a task
To change the interval of the daily summary or add a new task:
```bash
curl -X POST http://localhost:8080/scheduler/tasks \
     -H "Content-Type: application/json" \
     -d '{
       "name": "Generar resumen diario (cada minuto)", 
       "task": "generate_daily_summary", 
       "interval_seconds": 30, 
       "enabled": true
     }'
```

### Delete a task
```bash
curl -X DELETE "http://localhost:8080/scheduler/tasks/Generar%20resumen%20diario%20(cada%20minuto)"
```

*Note: Changes are picked up automatically by the Celery Beat container within seconds.*

## üìÇ Project Structure

- `api/`: FastAPI application code, models, and Celery task definitions.
- `nginx/`: Nginx configuration files.
- `shared/`: Local directory for files generated by background tasks (JSON summaries, CSV exports).
- `docker-compose.yml`: Full stack orchestration.
- `.flake8`: Linting configuration.
